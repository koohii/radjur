Hello

I need your help. I am building an application called "rÃ¥djur" for class that uses HTML5, Web audio API technology. I've built something in PureData not to long ago, but unfortunately wedPD don't have everything that I need in order to make the patch work, so I'm forced to use HTML5 and Web Audio API. 

My idea for this app is to have the user upload a song onto the application (kind of like Soundcloud.com or any of these stream audio websites). When the song is uploaded, the user has the ability to play the song from the browser and change the EQ of the song and record it onto a recorder in the browser and download it as a processed song.  

I'm using various users code to create something of my own, but i"m having a rough time connecting all in code. I'm using Matt Diamond's recorder code and Andre Michelle's Biquad filter code. The signal chain is simple. Play uploaded song, change EQ and record the processed song. It's kinda like audio mastering, but all in a browser.

As you notice when you open the file. A song is already uploaded. I did that so I can figure out how to connect the Audio EQ player to the recorder, but I've spent weeks on this application and I'm in a stand still.

Any help would be amazing. 
Thank you


P.S. I'm new to github, but i don't know how to create a folder. 
Before you start messing with the code. Make four folders with the following names, audio, img, js, css.
Place all files that are suppose to be in those folders I.E. JavaScript > js folder, MP3 WAV > audio folder, etc. 
That way, when you look at the index file on your web browser, everything would be there. 

Thanks! 
